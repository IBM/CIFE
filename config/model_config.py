
# model_configs = {
#     "meta-llama/Llama-3.1-8B-Instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-1-8b-instruct/v1",
#     "ibm-granite/granite-3.1-2b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-1-2b-instruct/v1",
#     "ibm-granite/granite-3.1-8b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-1-8b-instruct/v1",
#     "meta-llama/llama-3-3-70b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-3-70b-instruct/v1",
#     "mistralai/Mistral-Small-3.1-24B-Instruct-2503": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mistral-small-3-1-24b-2503/v1",
#     "ibm-granite/granite-3.3-8b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-3-8b-instruct/v1",
#     "microsoft/phi-4" : "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/microsoft-phi-4/v1",
#     "mistralai/mixtral-8x22B-instruct-v0.1": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x22b-instruct-v01/v1",
#     "mistralai/mixtral-8x7B-instruct-v0.1": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x7b-instruct-v01/v1",
#     "deepseek-ai/deepseek-coder-33b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/deepseek-coder-33b-instruct/v1"
# }
#  model_configs = {
#      "meta-llama/Llama-3.1-8B-Instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-1-8b-instruct/v1",
#           "codellama/CodeLlama-34b-Instruct-hf": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/codellama-34b-instruct-hf/v1",
#     "codellama/CodeLlama-70b-Instruct-hf": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/codellama-70b-instruct-hf/v1",
#       "microsoft/Phi-4-reasoning": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/phi-4-reasoning/v1",
#  }

# model_configs = {
#     "mistralai/mixtral-8x22B-instruct-v0.1": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x22b-instruct-v01/v1",
#     "mistralai/mixtral-8x7B-instruct-v0.1": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x7b-instruct-v01/v1",
#     "deepseek-ai/deepseek-coder-33b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/deepseek-coder-33b-instruct/v1"
# }



# model_configs = {
#     "meta-llama/Llama-3.1-8B-Instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-1-8b-instruct/v1",
#     "ibm-granite/granite-3.1-2b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-1-2b-instruct/v1",
#     "ibm-granite/granite-3.1-8b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-1-8b-instruct/v1",
#     "meta-llama/llama-3-3-70b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-3-70b-instruct/v1",
#     "mistralai/Mistral-Small-3.1-24B-Instruct-2503": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mistral-small-3-1-24b-2503/v1",
#     "ibm-granite/granite-3.3-8b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-3-8b-instruct/v1",
#     "microsoft/phi-4" : "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/microsoft-phi-4/v1",
#     "mistralai/mixtral-8x22B-instruct-v0.1": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x22b-instruct-v01/v1",
#     "mistralai/mixtral-8x7B-instruct-v0.1": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x7b-instruct-v01/v1",
#     "Qwen/Qwen3-8B": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/qwen3-8b/v1",
#     "deepseek-ai/deepseek-coder-33b-instruct": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/deepseek-coder-33b-instruct/v1"
# }


# model_configs = {
# "Qwen/Qwen3-8B": "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/qwen3-8b/v1"
# }

model_configs = {
    "gpt-4o-2024-08-06": None,
    "o1-mini-2024-09-12": None,
    "o3-mini": None,
    "granite-3.3-8b-instruct_reasoning":None
    }